{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, pickle\n",
    "sys.path.append(\"..\")\n",
    "import torch\n",
    "from trainer.recorder import Recorder\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import MAXYEAR, MINYEAR\n",
    "from datetime import datetime, time, timedelta\n",
    "\n",
    "def today():\n",
    "    today = datetime.now().date()\n",
    "    return datetime.combine(today, time.min)\n",
    "def days_ago(days):\n",
    "    day = today()\n",
    "    return day - timedelta(days=days)\n",
    "maxtime = datetime(MAXYEAR, 1, 1)\n",
    "mintime = datetime(MINYEAR, 1, 1)\n",
    "\n",
    "def stdmean(logger: Recorder, *labels, summarize=None):\n",
    "    '''\n",
    "    compute the stdmean of logged data with the given labels across all runs\n",
    "    customized by the `summarize` fn\n",
    "    '''\n",
    "    if summarize is None:\n",
    "        summarize = lambda x: x\n",
    "    series_dict = {}\n",
    "    for run in logger:\n",
    "        run_dict = logger.get_data(run, *labels)\n",
    "        summary_dict = summarize(run_dict)\n",
    "        for new_label in summary_dict:\n",
    "            if new_label not in series_dict:\n",
    "                series_dict[new_label] = []\n",
    "            series_dict[new_label].append(summary_dict[new_label])\n",
    "    stdmean_dict = {}\n",
    "    for label in series_dict:\n",
    "        t = torch.tensor(series_dict[label])\n",
    "        stdmean_dict[label] = [t.mean().item(), t.std().item()]\n",
    "    return stdmean_dict\n",
    "\n",
    "def stdmean_acc(logger: Recorder):\n",
    "    def get_acc(val_test):\n",
    "        val_acc = 100 * torch.tensor(val_test['val/acc'])\n",
    "        valid = val_acc.max().item()\n",
    "        test = 100 * val_test['test/acc'][val_acc.argmax()]\n",
    "        return {'val/acc' : valid, 'test/acc': test}\n",
    "    return stdmean(logger, 'val/acc', 'test/acc', summarize=get_acc)\n",
    "\n",
    "def select(loggers, filters: dict, time=None):\n",
    "    def match(to_match: dict, filters: dict):\n",
    "        assert isinstance(filters, dict)\n",
    "        for k in filters:\n",
    "            if k not in to_match:\n",
    "                return False\n",
    "            if isinstance(filters[k], dict):\n",
    "                if not match(to_match[k], filters[k]):\n",
    "                    return False\n",
    "            elif isinstance(filters[k], list) or isinstance(filters[k], tuple):\n",
    "                for i, f in enumerate(filters[k]):\n",
    "                    if not match(to_match[k][i], f):\n",
    "                        return False\n",
    "            else:\n",
    "                if to_match[k] != filters[k]:\n",
    "                    return False\n",
    "        return True\n",
    "    filtered = [\n",
    "        logger for logger in loggers if match(logger.info, filters)\n",
    "    ]\n",
    "    if time is not None:\n",
    "        start, end = time\n",
    "        filtered = [\n",
    "            logger for logger in filtered if logger.time < end and logger.time >= start\n",
    "        ]\n",
    "    return filtered\n",
    "\n",
    "import glob\n",
    "def load_logs(dir):\n",
    "    def load_pkl(fname):\n",
    "        with open(fname, 'rb') as fp:\n",
    "            logs = pickle.load(fp)\n",
    "            logs.fname = fname.split('/')[-1]\n",
    "            logs.time = datetime.fromtimestamp(os.path.getmtime(fname)).replace(microsecond=0)\n",
    "            if not isinstance(logs.info, dict):\n",
    "                logs.info = vars(logs.info)\n",
    "            return logs\n",
    "    files = glob.glob(dir)\n",
    "    return [load_pkl(f) for f in files]\n",
    "\n",
    "def extract_acc_curve(logs: list[Recorder], key_fn=None):\n",
    "    logs = sorted(logs, key=lambda log: key_fn(log.info))\n",
    "    proc_data = {}\n",
    "    for log in logs:\n",
    "        block_info =  key_fn(log.info)\n",
    "        acc_keys = ('train/acc', 'val/acc', 'test/acc')\n",
    "        proc_data[block_info] = {\n",
    "            k: [] for k in acc_keys\n",
    "        }\n",
    "        for run in log:\n",
    "            run_acc = log.get_data(run, *acc_keys)\n",
    "            for k in acc_keys:\n",
    "                proc_data[block_info][k].append(run_acc[k])\n",
    "    return proc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = load_logs('../logdir/acc_study/*')\n",
    "mts = select(logs, {\n",
    "    'dataset': 'ogbn-arxiv_r',\n",
    "    'hb': 'metis',\n",
    "    })\n",
    "for log in mts:\n",
    "    print(log.time,  log.info, log.stdmean())\n",
    "fnl = select(logs, {\n",
    "    'dataset': 'ogbn-arxiv_r',\n",
    "    'hb': 'fennel',\n",
    "    })\n",
    "for log in fnl:\n",
    "    print(log.time, log.info, log.stdmean())\n",
    "# fnllb = select(logs, {\n",
    "#     'dataset': {'root': '/mnt/md0/hb_datasets/ogbn_arxiv'},\n",
    "#     'model': {'arch': 'sage', 'epochs': 100},\n",
    "#     'sample': {'train': [{'partition': 'fennel-lb', 'num_repeats': 2}]},\n",
    "#     })\n",
    "# for log in fnllb:\n",
    "#     print(log.time, log.info['sample'], log.stdmean())\n",
    "\n",
    "def key_fn(info):\n",
    "    return info['dataset'], info['num_blocks'], info['num_blocks'] // info['block_ratio']\n",
    "\n",
    "acc_series = {\n",
    "    'HB-metis': extract_acc_curve(mts, key_fn),\n",
    "    'HB-lb': extract_acc_curve(fnl, key_fn),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = load_logs('../logdir/acc/*')\n",
    "ns = select(logs, {\n",
    "    'dataset': {'root': '/mnt/md0/hb_datasets/ogbn_arxiv'},\n",
    "    'model': {'arch': 'sage', 'epochs': 100},\n",
    "    'sample': {'train': [{'sampler': 'ns'}]},\n",
    "    })\n",
    "for log in ns:\n",
    "    print(log.time,  log.info['sample'], log.stdmean())\n",
    "mts = select(logs, {\n",
    "    'dataset': {'root': '/mnt/md0/hb_datasets/ogbn_arxiv'},\n",
    "    'model': {'arch': 'sage', 'epochs': 100},\n",
    "    'sample': {'train': [{'partition': 'metis', 'num_repeats': 2}]},\n",
    "    })\n",
    "for log in mts:\n",
    "    print(log.time,  log.info['sample'], log.stdmean())\n",
    "fnl = select(logs, {\n",
    "    'dataset': {'root': '/mnt/md0/hb_datasets/ogbn_arxiv'},\n",
    "    'model': {'arch': 'sage', 'epochs': 100},\n",
    "    'sample': {'train': [{'partition': 'fennel', 'num_repeats': 2}]},\n",
    "    })\n",
    "for log in fnl:\n",
    "    print(log.time, log.info['sample'], log.stdmean())\n",
    "fnllb = select(logs, {\n",
    "    'dataset': {'root': '/mnt/md0/hb_datasets/ogbn_arxiv'},\n",
    "    'model': {'arch': 'sage', 'epochs': 100},\n",
    "    'sample': {'train': [{'partition': 'fennel-lb', 'num_repeats': 2}]},\n",
    "    })\n",
    "for log in fnllb:\n",
    "    print(log.time, log.info['sample'], log.stdmean())\n",
    "rnd = select(logs, {\n",
    "    'dataset': {'root': '/mnt/md0/hb_datasets/ogbn_arxiv'},\n",
    "    'model': {'arch': 'sage', 'epochs': 100},\n",
    "    'sample': {'train': [{'partition': 'rand', 'num_repeats': 2}]},\n",
    "    })\n",
    "for log in rnd:\n",
    "    print(log.time, log.info['sample'], log.stdmean())\n",
    "\n",
    "def key_fn(info):\n",
    "    cluster_info = info['sample']['train'][0]\n",
    "    return cluster_info['P'], cluster_info['batch_size'], cluster_info['num_repeats']\n",
    "acc_series = {\n",
    "    'NS': extract_acc_curve(ns, lambda x: 'NS'),\n",
    "    'HB-metis': extract_acc_curve(mts, key_fn),\n",
    "    'HB-lb': extract_acc_curve(fnllb, key_fn),\n",
    "    'HB-no-lb': extract_acc_curve(fnl, key_fn),\n",
    "    'HB-marius': extract_acc_curve(rnd, key_fn),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.interpolate import make_interp_spline\n",
    "def make_conv_figure(axs, shfl_method, ylim=[0.5, 0.8], stderr=True):\n",
    "    plt.ylim(ylim)\n",
    "    # for i, acc_type in enumerate(('train/acc', 'val/acc')):\n",
    "    for i, acc_type in enumerate(('val/acc', 'test/acc')):\n",
    "        ax = axs[i]\n",
    "        ax.set_title(acc_type)\n",
    "        ax.margins(x=0)\n",
    "        acc_blocks = acc_series[shfl_method]\n",
    "        for block_info in acc_blocks:\n",
    "            acc_curves = torch.tensor(acc_blocks[block_info][acc_type])\n",
    "            xs = range(acc_curves.size(1))\n",
    "            mean = acc_curves.mean(dim=0)\n",
    "            std = acc_curves.std(dim=0)\n",
    "            interp_xs = torch.arange(0, mean.size(0)-1, mean.size(0)/1000)\n",
    "            lower = make_interp_spline(xs, mean-std)(interp_xs)\n",
    "            upper = make_interp_spline(xs, mean+std)(interp_xs)\n",
    "            mean = make_interp_spline(xs, mean)(interp_xs)\n",
    "            label = shfl_method\n",
    "            if 'HB' in shfl_method:\n",
    "                label += f' {block_info}'.replace(', ', '/')\n",
    "            if stderr:\n",
    "                if 'GS' in shfl_method:\n",
    "                    ax.plot(interp_xs, mean, marker=',', label=label, color='red', ls='-', lw=2)\n",
    "                else:\n",
    "                    ax.plot(interp_xs, mean, marker=',', label=label)\n",
    "                ax.fill_between(interp_xs, lower, upper, alpha=0.1, interpolate=True)\n",
    "            else:\n",
    "                ax.plot(acc_curves[2][:25], marker=',', label=label, ls='-', lw=1)\n",
    "\n",
    "    ax.legend(fontsize=12)\n",
    "\n",
    "# fig, axs = plt.subplots(1, 3, figsize=(18, 18), sharey='row', dpi=200)\n",
    "# fig.tight_layout()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4), sharey='row', squeeze=False)\n",
    "# fig.suptitle(f\"Model Convergence under Different Shuffling Schemes\", fontsize=20)\n",
    "# fig.subplots_adjust(top=0.92)\n",
    "# for ax, title in zip(axs[0], ('val/acc', 'test/acc')):\n",
    "#     ax.set_title(title, fontsize=20)\n",
    "for ax in axs[:,0]:\n",
    "    ax.set_ylabel('accuracy', fontsize=20)\n",
    "for ax in axs[-1]:\n",
    "    ax.set_xlabel('epoch', fontsize=20)\n",
    "\n",
    "for k in acc_series:\n",
    "    make_conv_figure(axs[0], shfl_method=k, stderr=False)\n",
    "plt.show()\n",
    "# fig.savefig(\n",
    "#     'label_accuracy.pdf', bbox_inches = \"tight\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emd_dict = {\n",
    "    'random hier-batching': {\n",
    "        (64,4): 2.2e-3,\n",
    "        (64,8): 2.2e-3,\n",
    "        (64,16): 2.2e-3,\n",
    "    },\n",
    "    'metis hier-batching': {\n",
    "        (64,4): 9.2e-3,\n",
    "        (64,8): 6.9e-3,\n",
    "        (64,16): 4.4e-3,\n",
    "        # (1024,64): 4.2e-3,\n",
    "        # (1024,128): 3.3e-3,\n",
    "        # (1024,256): 2.8e-3,\n",
    "    },\n",
    "    'fennel-LB hier-batching': {\n",
    "        (64,4): 2.2e-3,\n",
    "        (64,8): 2.1e-3,\n",
    "        (64,16): 2.1e-3,\n",
    "        (1024,16): 2.1e-3,\n",
    "    },\n",
    "    'global shuffling': {\n",
    "        (64,8): 2.1e-3,\n",
    "    },\n",
    "    'shuffling once': {\n",
    "        (64,8): 2.1e-3,\n",
    "    }\n",
    "}\n",
    "\n",
    "def extract_acc(logs: list[Recorder]):\n",
    "    acc_dict = {}\n",
    "    for log in logs:\n",
    "        info = log.info\n",
    "        block_info = info.num_blocks, info.num_blocks // info.block_ratio\n",
    "        acc_dict[block_info] = stdmean_acc(log)\n",
    "    return acc_dict\n",
    "\n",
    "acc_method_dict = {\n",
    "    'random hier-batching': extract_acc(rd_logs),\n",
    "    'metis hier-batching': extract_acc(hb_logs),\n",
    "    'fennel-LB hier-batching': extract_acc(fl_logs),\n",
    "    'global shuffling': extract_acc(gs_logs),\n",
    "    # 'shuffling once': extract_acc(ss_logs),\n",
    "}\n",
    "\n",
    "style_dict = {\n",
    "    'random hier-batching': {'marker': 'o', 'color': 'green'},\n",
    "    'metis hier-batching': {'marker': '^', 'color': 'blue'},\n",
    "    'fennel-LB hier-batching': {'marker': 'v', 'color': 'brown'},\n",
    "    'global shuffling': {'marker': 'D', 'color': 'red'},\n",
    "    'shuffling once': {'marker': 'h', 'color': 'orange'},\n",
    "}\n",
    "\n",
    "def make_acc_figure(ax, label, ylim=[68, 74], set_label=False):\n",
    "    plt.ylim(ylim)\n",
    "    for shfl_method in acc_method_dict:\n",
    "        acc_dict = acc_method_dict[shfl_method]\n",
    "        _set_label = set_label\n",
    "        for block_info in acc_dict:\n",
    "            if block_info[0] == block_info[1]:\n",
    "                continue\n",
    "            if block_info not in emd_dict[shfl_method]:\n",
    "                continue\n",
    "            mean, std = acc_dict[block_info][label]\n",
    "            emd = emd_dict[shfl_method][block_info]\n",
    "            if _set_label:\n",
    "                ax.errorbar([emd], [mean], yerr=[std], capsize=3, **style_dict[shfl_method], label=shfl_method)\n",
    "                _set_label = False\n",
    "            else:\n",
    "                ax.errorbar([emd], [mean], yerr=[std], capsize=3, **style_dict[shfl_method])\n",
    "    if set_label:\n",
    "        ax.legend(fontsize=12)\n",
    "    ax.set_title(label, fontsize=16)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4), sharex=True, dpi=160)\n",
    "fig.tight_layout()\n",
    "fig.suptitle(f\"Model Accuracy / Mini-batch Label Discrepancy\", fontsize=16)\n",
    "fig.subplots_adjust(top=0.85)\n",
    "make_acc_figure(axs[0], 'val/acc', ylim=[70, 73], set_label=True)\n",
    "make_acc_figure(axs[1], 'test/acc', ylim=[69, 72])\n",
    "axs[0].set_ylabel('accuracy', fontsize=16)\n",
    "fig.text(0.5, -0.04, 'mean discrepancy of label distribution', ha='center', fontsize=16)\n",
    "fig.savefig(\"label_discrepancy.pdf\", bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
