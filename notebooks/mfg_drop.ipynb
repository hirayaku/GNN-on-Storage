{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Study of Lossy MFG\n",
    "\n",
    "We select some non-training nodes in MFG and drop their incoming edges to simulate the effects of node partitioning.\n",
    "\n",
    "There may be several strategies for choosing those nodes:\n",
    "* random\n",
    "* random but excluding important (i.e. high-degree) nodes\n",
    "* based on the influence score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torch, torch_geometric as pyg\n",
    "import models.pyg as pyg_models\n",
    "\n",
    "print(\"PyTorch:\", torch.__version__, *torch.__path__)\n",
    "print(\"PyG:\", pyg.__version__, *pyg.__path__)\n",
    "print(\"CPU parallelism:\", torch.get_num_threads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets.reddit import Reddit\n",
    "from torch_geometric.utils import mask_to_index\n",
    "from torch_geometric.loader import NeighborLoader, NeighborSampler\n",
    "from logger import Logger\n",
    "import pickle\n",
    "\n",
    "path = Path('/mnt/md0/datasets/')\n",
    "\n",
    "# name = 'arxiv'\n",
    "# dataset = PygNodePropPredDataset(\n",
    "#     root=path, name='ogbn-arxiv',\n",
    "#     pre_transform=T.ToUndirected(),\n",
    "#     transform=T.ToSparseTensor()\n",
    "# )\n",
    "# data = dataset[0]\n",
    "# data.NID = torch.arange(0, data.num_nodes, dtype=torch.int32)\n",
    "# num_classes = dataset.num_classes\n",
    "# print(data)\n",
    "# split = dataset.get_idx_split()\n",
    "# train_nid, val_nid, test_nid = split['train'], split['valid'], split['test']\n",
    "\n",
    "name = 'reddit'\n",
    "dataset = Reddit(path / name, pre_transform=T.AddSelfLoops(), transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "data.NID = torch.arange(0, data.num_nodes, dtype=torch.int32)\n",
    "num_classes = dataset.num_classes\n",
    "print(data)\n",
    "if os.path.exists(f'{name}_rand_split.pt'):\n",
    "    perm = torch.load(f'{name}_rand_split.pt')\n",
    "else:\n",
    "    perm = torch.randperm(data.num_nodes)\n",
    "    torch.save(perm, f'{name}_rand_split.pt')\n",
    "train_nid = perm[:data.num_nodes//10]\n",
    "val_nid = perm[data.num_nodes//2:]\n",
    "test_nid = perm[data.num_nodes//10:data.num_nodes//2]\n",
    "\n",
    "print(f\"train: {len(train_nid)}, val: {len(val_nid)}, test: {len(test_nid)}\")\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "num_layers = 3\n",
    "num_hidden = 128\n",
    "fanout = [-1] * num_layers\n",
    "eval_fanout = [-1] * num_layers\n",
    "batch_size = 4096\n",
    "n_epochs = 50\n",
    "n_runs = 5\n",
    "\n",
    "def get_info():\n",
    "    return {\n",
    "        'dataset': dataset.name,\n",
    "        'num_layers': num_layers, 'num_hidden': num_hidden,\n",
    "        'fanout': fanout, 'batch_size': batch_size,\n",
    "        'n_epochs': n_epochs, 'n_runs': n_runs\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphutils.rw import lazy_rw\n",
    "\n",
    "def influential(data, nids, k=3, topk=100):\n",
    "    init_score = torch.zeros((data.num_nodes,), device=nids.device)\n",
    "    init_score[nids] = 1 / nids.size(0)\n",
    "    final_score = lazy_rw(data.adj_t, init_score, k=k)\n",
    "    topk = final_score.cpu().topk(topk)\n",
    "    # print(\"score sum:\", final_score.sum(), \"topk sum:\", topk.values.sum())\n",
    "    return topk.indices, topk.values\n",
    "\n",
    "def importance(data, nids, k=3, topk=100):\n",
    "    init_score = torch.zeros((data.num_nodes,), device=nids.device)\n",
    "    init_score[nids] = 1 / nids.size(0)\n",
    "    final_score = torch.zeros_like(init_score)\n",
    "    score = init_score\n",
    "    for _ in range(k):\n",
    "        score = lazy_rw(data.adj_t, score, k=1)\n",
    "        final_score += score\n",
    "    topk = (final_score/k).cpu().topk(topk)\n",
    "    # print(\"score sum:\", final_score.sum(), \"topk sum:\", topk.values.sum())\n",
    "    return topk.indices, topk.values\n",
    "\n",
    "data_cuda = data.cuda()\n",
    "train_cuda = train_nid.cuda()\n",
    "pt_name = f'train_topk_infl_{name}.pt'\n",
    "if os.path.exists(pt_name):\n",
    "    train_topk, train_topk_scores = torch.load(pt_name)\n",
    "else:\n",
    "    train_topk = torch.empty((data.num_nodes, 100), dtype=torch.long)\n",
    "    train_topk_scores = torch.empty((data.num_nodes, 100), dtype=torch.float)\n",
    "    from tqdm import tqdm\n",
    "    for t in tqdm(train_cuda.tolist()):\n",
    "        t_topk = influential(data_cuda, torch.tensor([t], device='cuda'), k=3, topk=100)\n",
    "        train_topk[t][:] = t_topk[0]\n",
    "        train_topk_scores[t][:] = t_topk[1]\n",
    "    torch.save([train_topk, train_topk_scores], pt_name)\n",
    "\n",
    "train_topk, train_topk_scores = train_topk.cuda(), train_topk_scores.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from pyinstrument import Profiler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# val_dataloader = NeighborLoader(\n",
    "#     data, num_neighbors=fanout, shuffle=False,\n",
    "#     input_nodes=val_nid, batch_size=batch_size,\n",
    "# )\n",
    "# test_dataloader = NeighborLoader(\n",
    "#     data, num_neighbors=fanout, shuffle=False,\n",
    "#     input_nodes=test_nid, batch_size=batch_size,\n",
    "# )\n",
    "\n",
    "def train(model, optimizer, dataloader, description='train'):\n",
    "    model.train()\n",
    "    # minibatches = tqdm.tqdm(dataloader)\n",
    "    # minibatches.set_description(description)\n",
    "    total_loss = total_correct = total_examples = 0\n",
    "    mfg_sizes = num_nodes = alive_nodes = batch_score = 0\n",
    "    for batch in dataloader:\n",
    "        bsize = batch.batch_size\n",
    "        dev_attrs = [key for key in batch.keys if not key.endswith('_mask')]\n",
    "        batch = batch.to(device, *dev_attrs, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "        y = batch.y[:bsize].long().view(-1)\n",
    "        y_hat = model(batch.x, batch.adj_t)[:bsize]\n",
    "        loss = F.nll_loss(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # collect stats\n",
    "        total_loss += float(loss) * bsize\n",
    "        batch_correct = int((y_hat.argmax(dim=-1) == y).sum())\n",
    "        total_correct += batch_correct\n",
    "        total_examples += bsize\n",
    "        mfg_sizes += batch.adj_t.nnz()\n",
    "        num_nodes += batch.num_nodes\n",
    "        alive_nodes += batch.alive_nodes\n",
    "        batch_score += batch.score\n",
    "    train_acc = total_correct / total_examples\n",
    "    num_iters = len(dataloader)\n",
    "    # loss, acc, batch_nodes, rem_nodes, rem_edges, batch_score\n",
    "    return total_loss / total_examples, train_acc, \\\n",
    "        num_nodes/num_iters, alive_nodes / num_iters, \\\n",
    "        mfg_sizes / num_iters, batch_score / total_examples\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_batch(model, dataloader, description='eval'):\n",
    "    model.eval()\n",
    "    minibatches = tqdm.tqdm(dataloader)\n",
    "    total_loss = total_correct = total_examples = 0\n",
    "    for batch in minibatches:\n",
    "        bsize = batch.batch_size\n",
    "        dev_attrs = [key for key in batch.keys if not key.endswith('_mask')]\n",
    "        batch = batch.to(device, *dev_attrs, non_blocking=True)\n",
    "        y = batch.y[:bsize].long().view(-1)\n",
    "        y_hat = model(batch.x, batch.adj_t)[:bsize]\n",
    "        loss = F.nll_loss(y_hat, y)\n",
    "        # collect stats\n",
    "        total_loss += float(loss) * bsize\n",
    "        batch_correct = int((y_hat.argmax(dim=-1) == y).sum())\n",
    "        total_correct += batch_correct\n",
    "        total_examples += bsize\n",
    "    train_acc = total_correct / total_examples\n",
    "    return total_loss / total_examples, train_acc\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_full(model, data, masks, description='eval'):\n",
    "    model.eval()\n",
    "    y_hat = model(data.x.cuda(), data.adj_t.cuda())\n",
    "    out = []\n",
    "    for mask in masks:\n",
    "        y = data.y[mask].long().view(-1)\n",
    "        loss = float(F.nll_loss(y_hat[mask], y))\n",
    "        acc = int((y_hat[mask].argmax(dim=-1) == y).sum()) / y.shape[0]\n",
    "        out.append((loss, acc))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch_sparse import SparseTensor\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# dropping strategies\n",
    "\n",
    "# random drop node with prob roughly p\n",
    "def drop_random(batch, p: float) -> Data:\n",
    "    bn = batch.adj_t.sizes()[0]\n",
    "    device = batch.adj_t.device()\n",
    "    node_mask = torch.ones((bn,), dtype=torch.bool, device=device)\n",
    "    n_drop = int((bn - batch.batch_size) * p)\n",
    "    if p < 0.25:\n",
    "        dropped = torch.randint(batch.batch_size, bn, size=(n_drop,), device=device)\n",
    "    else:\n",
    "        dropped = torch.randperm(bn-batch.batch_size)[:n_drop] + batch.batch_size\n",
    "    node_mask[dropped] = False\n",
    "\n",
    "    n = data.num_nodes\n",
    "    n_score: torch.Tensor = torch.zeros(n, device=device)\n",
    "    target_id = batch.n_id[:batch.batch_size]\n",
    "    topk_nids = train_topk[target_id].view(-1)\n",
    "    topk_scores = train_topk_scores[target_id].view(-1)\n",
    "    n_score.scatter_add_(dim=0, index=topk_nids, src=topk_scores)\n",
    "    n_score = n_score[batch.n_id]\n",
    "    batch.n_score = n_score\n",
    "\n",
    "    src, dst, _ = batch.adj_t.coo()\n",
    "    mask = node_mask[src]\n",
    "    mask &= node_mask[dst]\n",
    "    batch.adj_t = SparseTensor(\n",
    "        row=src[mask], col=dst[mask],\n",
    "        sparse_sizes=batch.adj_t.sizes(),\n",
    "        is_sorted=True,\n",
    "    )\n",
    "    batch.node_mask = node_mask\n",
    "    return batch\n",
    "\n",
    "# drop based on train_topk, train_topk_scores\n",
    "def drop_by_influence(batch, p: float):\n",
    "    bn = batch.adj_t.sizes()[0]\n",
    "    device = batch.adj_t.device()\n",
    "    node_mask = torch.zeros((bn,), dtype=torch.bool, device=device) \n",
    "    n_drop = int((bn - batch.batch_size) * p)\n",
    "\n",
    "    # select top-k nodes in batch by score\n",
    "    n = data.num_nodes\n",
    "    n_score: torch.Tensor = torch.zeros(n, device=device)\n",
    "    target_id = batch.n_id[:batch.batch_size]\n",
    "    topk_nids = train_topk[target_id].view(-1)\n",
    "    topk_scores = train_topk_scores[target_id].view(-1)\n",
    "    n_score.scatter_add_(dim=0, index=topk_nids, src=topk_scores)\n",
    "    n_score = n_score[batch.n_id]\n",
    "    batch.n_score = n_score\n",
    "    node_mask[n_score.topk(bn-n_drop).indices] = True\n",
    "\n",
    "    src, dst, _ = batch.adj_t.coo()\n",
    "    mask = node_mask[dst]\n",
    "    mask &= node_mask[src]\n",
    "    batch.adj_t = SparseTensor(\n",
    "        row=src[mask], col=dst[mask],\n",
    "        sparse_sizes=batch.adj_t.sizes(),\n",
    "        is_sorted=True,\n",
    "    )\n",
    "    batch.node_mask = node_mask\n",
    "    return batch\n",
    "\n",
    "def drop_hop(batch, p: float, hop=1) -> Data:\n",
    "    '''\n",
    "    only drop nodes that are not immediate neighbors of target nodes in the mfg\n",
    "    '''\n",
    "    def hop_bound(hop_num):\n",
    "        src, dst, _ = batch.adj_t.coo()\n",
    "        hop_i = 0\n",
    "        node_bound = batch.batch_size\n",
    "        while hop_i < hop_num:\n",
    "            edge_bound = (src < node_bound).sum().item()\n",
    "            node_bound = dst[:edge_bound].max().item() + 1\n",
    "            hop_i += 1\n",
    "        return node_bound\n",
    "\n",
    "    bn = batch.adj_t.sizes()[0]\n",
    "    device = batch.adj_t.device()\n",
    "    node_mask = torch.ones((bn,), dtype=torch.bool, device=device) \n",
    "    n_drop = int((bn - batch.batch_size) * p)\n",
    "\n",
    "    n_close = hop_bound(hop)\n",
    "    if n_drop < bn - n_close:\n",
    "        dropped = torch.randperm(bn-n_close)[:n_drop] + n_close\n",
    "        node_mask[dropped] = False\n",
    "    else:\n",
    "        node_mask[torch.arange(n_close, bn)] = False\n",
    "        drop_more = n_drop - (bn - n_close)\n",
    "        dropped = torch.randperm(n_close - batch.batch_size)[:drop_more] + batch.batch_size\n",
    "        node_mask[dropped] = False\n",
    "\n",
    "    # select top-k nodes in batch by score\n",
    "    n = data.num_nodes\n",
    "    n_score: torch.Tensor = torch.zeros(n, device=device)\n",
    "    target_id = batch.n_id[:batch.batch_size]\n",
    "    topk_nids = train_topk[target_id].view(-1)\n",
    "    topk_scores = train_topk_scores[target_id].view(-1)\n",
    "    n_score.scatter_add_(dim=0, index=topk_nids, src=topk_scores)\n",
    "    n_score = n_score[batch.n_id]\n",
    "    batch.n_score = n_score\n",
    "\n",
    "    src, dst, _ = batch.adj_t.coo()\n",
    "    mask = node_mask[dst]\n",
    "    mask &= node_mask[src]\n",
    "    batch.adj_t = SparseTensor(\n",
    "        row=src[mask], col=dst[mask],\n",
    "        sparse_sizes=batch.adj_t.sizes(),\n",
    "        is_sorted=True,\n",
    "    )\n",
    "    batch.node_mask = node_mask\n",
    "    return batch\n",
    "\n",
    "def transform_fn(batch, drop_fn, k=3):\n",
    "    batch = drop_fn(batch)\n",
    "    batch.score = batch.n_score[batch.node_mask].sum().item()\n",
    "    batch.alive_nodes = int(batch.node_mask.sum())\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.utils import degree\n",
    "# from functools import lru_cache\n",
    "\n",
    "# data_degrees = degree(data.adj_t.coo()[0], data.num_nodes, dtype=torch.int32)\n",
    "# @lru_cache\n",
    "# def topk_degree(topk):\n",
    "#     return torch.topk(data_degrees, int(topk * data.num_nodes)).values[-1]\n",
    "# def drop_minor(batch, p: float, topk=0.01) -> Data:\n",
    "#     '''\n",
    "#     only drop nodes that are not important, i.e. of low degree\n",
    "#     '''\n",
    "#     if p == 0:\n",
    "#         batch.drop_nodes = 0\n",
    "#         return batch\n",
    "#     num_nodes = batch.adj_t.sizes()[0]\n",
    "#     node_mask = torch.ones((num_nodes,), dtype=torch.bool)\n",
    "#     drop_nodes = torch.from_numpy(np.random.choice(\n",
    "#         torch.arange(batch.batch_size, num_nodes).numpy(),\n",
    "#         size=int((num_nodes - batch.batch_size) * p),\n",
    "#         replace=False\n",
    "#     ))\n",
    "#     node_mask[drop_nodes] = False\n",
    "#     topk_cutout = topk_degree(topk)\n",
    "#     node_mask |= (data_degrees[batch.NID.long()] >= topk_cutout)\n",
    "#     src, dst, _ = batch.adj_t.coo()\n",
    "#     mask = torch.gather(input=node_mask, dim=0, index=src)\n",
    "#     mask = mask & torch.gather(input=node_mask, dim=0, index=dst)\n",
    "#     batch.adj_t = SparseTensor(\n",
    "#         row=src[mask], col=dst[mask],\n",
    "#         sparse_sizes=batch.adj_t.sizes(),\n",
    "#         is_sorted=True\n",
    "#     )\n",
    "#     batch.node_mask = node_mask\n",
    "#     return batch\n",
    "\n",
    "# def compute_score(batch):\n",
    "#     '''\n",
    "#     compute the importance score of each node in the current batch\n",
    "#     '''\n",
    "#     num_nodes = batch.num_nodes\n",
    "#     e_t = torch.zeros((num_nodes,), dtype=torch.float)\n",
    "#     e_t[:batch.batch_size] = 1\n",
    "#     deg = degree(batch.adj_t.coo()[0], batch.num_nodes)\n",
    "#     deg[deg==0] = 1\n",
    "#     adj = batch.adj_t.t()\n",
    "#     scores = [e_t]\n",
    "#     for _ in range(3):\n",
    "#         pi = scores[-1] / deg\n",
    "#         scores.append(adj.spmm(pi.view(num_nodes, 1)).view(-1))\n",
    "#     per_node = sum(scores[1:])\n",
    "#     return per_node / per_node.sum()\n",
    "\n",
    "# def transform_fn(batch, drop_fn):\n",
    "#     score = compute_score(batch)\n",
    "#     batch = drop_fn(batch)\n",
    "#     batch.quality_score = score[batch.node_mask].sum().item()\n",
    "#     batch.alive_nodes = int(batch.node_mask.sum())\n",
    "#     return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_drop(data, drop_p, fn=drop_random, print_once=False):\n",
    "    model = pyg_models.SAGE(data.x.shape[1], num_hidden, num_classes, num_layers)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    drop_fn = lambda batch: fn(batch, drop_p)\n",
    "    transform = lambda batch: transform_fn(batch, drop_fn)\n",
    "    dataloader = NeighborLoader(\n",
    "        data, num_neighbors=fanout, shuffle=True,\n",
    "        input_nodes=train_nid, batch_size=batch_size,\n",
    "        transform=transform,\n",
    "        # num_workers=torch.get_num_threads()-2,\n",
    "        # persistent_workers=True\n",
    "    )\n",
    "\n",
    "    logger = Logger(get_info() | {'drop_p': drop_p, \"method\": fn.__name__})\n",
    "    print(logger.info)\n",
    "    for run in range(n_runs):\n",
    "        logger.set_run(run)\n",
    "        model.reset_parameters()\n",
    "        best_val = final_test = 0\n",
    "        best_epoch = 0\n",
    "        pbar = tqdm.tqdm(range(n_epochs))\n",
    "        description = '{:.4f}|{:.4f}|{:.4f}'\n",
    "        pbar.set_description(f\"Run {run}\")\n",
    "        pbar.set_postfix({'acc': description.format(0, best_val, 0)})\n",
    "        for epoch in pbar:\n",
    "            # if epoch < 2:\n",
    "            #     profiler = Profiler()\n",
    "            #     profiler.start()\n",
    "            train_loss, train_acc, *info = train(model, optimizer, dataloader, description=f\"Epoch {epoch}\")\n",
    "            if print_once:\n",
    "                # batch_nodes, rem_nodes, rem_edges, batch_score\n",
    "                print(info)\n",
    "                print_once = False\n",
    "            logger.add(epoch, data={'train': {'acc': train_acc, 'loss': train_loss, 'extra': info}})\n",
    "            val, test = eval_full(model, data, [val_nid, test_nid])\n",
    "            logger.add(epoch, data={\n",
    "                'val': {'loss': val[0], 'acc': val[1]},\n",
    "                'test': {'loss': test[0], 'acc': test[1]},\n",
    "            })\n",
    "            if val[1] > best_val:\n",
    "                best_val, final_test = val[1], test[1]\n",
    "                best_epoch = epoch\n",
    "            pbar.set_postfix({'acc': description.format(train_acc, best_val, final_test)})\n",
    "            # if epoch < 2:\n",
    "            #     profiler.stop()\n",
    "            #     profiler.print()\n",
    "        pbar.close()\n",
    "        logger.add(epoch, data={'best-epoch': best_epoch})\n",
    "    # explicitly shutdown workers when persistent_workers is True\n",
    "    del dataloader._iterator\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = [0.98, 0.95, 0.9, 0.8, 0.7, 0.5, 0]\n",
    "n_runs = 5\n",
    "n_epochs = 50\n",
    "loggers = [train_with_drop(data, drop_p=p, fn=drop_random, print_once=True) for p in ps]\n",
    "with open(f\"{name}_drop_random.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(loggers, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = [0.98, 0.95, 0.9, 0.8, 0.7, 0.5, 0]\n",
    "n_runs = 5\n",
    "n_epochs = 50\n",
    "loggers = [train_with_drop(data, drop_p=p, fn=drop_by_influence, print_once=True) for p in ps]\n",
    "with open(f\"{name}_drop_infl.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(loggers, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = [0.98, 0.95, 0.9, 0.8, 0.7, 0.5, 0]\n",
    "n_runs = 5\n",
    "n_epochs = 50\n",
    "loggers = [train_with_drop(data, drop_p=p, fn=drop_hop, print_once=True) for p in ps]\n",
    "with open(f\"{name}_drop_hop.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(loggers, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps = [0.98, 0.95, 0.9, 0.8, 0.7, 0.5, 0]\n",
    "# n_runs = 5\n",
    "# n_epochs = 50\n",
    "ps = [0.99]\n",
    "n_runs = 1\n",
    "n_epochs = 50\n",
    "loggers = [train_with_drop(data, drop_p=p, fn=drop_by_influence, print_once=True) for p in ps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = [0.95]\n",
    "n_runs = 1\n",
    "n_epochs = 50\n",
    "loggers = [train_with_drop(data, drop_p=p, fn=drop_random, print_once=True) for p in ps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdmean(logger: Logger, *labels, summarize=None):\n",
    "    '''\n",
    "    compute the stdmean of logged data with the given labels across all runs\n",
    "    customized by the `summarize` fn\n",
    "    '''\n",
    "    if summarize is None:\n",
    "        summarize = lambda x: x\n",
    "    series_dict = {}\n",
    "    for run in logger:\n",
    "        run_dict = logger.get_data(run, *labels)\n",
    "        summary_dict = summarize(run_dict)\n",
    "        for new_label in summary_dict:\n",
    "            if new_label not in series_dict:\n",
    "                series_dict[new_label] = []\n",
    "            series_dict[new_label].append(summary_dict[new_label])\n",
    "    stdmean_dict = {}\n",
    "    for label in series_dict:\n",
    "        t = torch.tensor(series_dict[label])\n",
    "        stdmean_dict[label] = [t.mean().item(), t.std().item()]\n",
    "    return stdmean_dict\n",
    "\n",
    "def stdmean_acc(logger: Logger):\n",
    "    def get_acc(val_test):\n",
    "        val_acc = 100 * torch.tensor(val_test['val/acc'])\n",
    "        valid = val_acc.max().item()\n",
    "        test = 100 * val_test['test/acc'][val_acc.argmax()]\n",
    "        return {'val/acc' : valid, 'test/acc': test}\n",
    "    return stdmean(logger, 'val/acc', 'test/acc', summarize=get_acc)\n",
    "\n",
    "import pickle\n",
    "loggers = {}\n",
    "with open(f'{name}_drop_random.pkl', 'rb') as fp:\n",
    "    loggers['random'] = pickle.load(fp)\n",
    "with open(f'{name}_drop_infl.pkl', 'rb') as fp:\n",
    "    loggers['influence'] = pickle.load(fp)\n",
    "with open(f'{name}_drop_hop.pkl', 'rb') as fp:\n",
    "    loggers['neighbor'] = pickle.load(fp)\n",
    "\n",
    "\n",
    "def extract_train_info(train_extra):\n",
    "    ext_list = list(zip(*train_extra['train/extra']))\n",
    "    # batch_nodes, rem_nodes, rem_edges, batch_score\n",
    "    return {\n",
    "        # 'batch_nodes': ext_list[0],\n",
    "        'rem_nodes': ext_list[1],\n",
    "        'rem_edges': ext_list[2],\n",
    "        'coverage': ext_list[3],\n",
    "    }\n",
    "\n",
    "proc_data = {}\n",
    "for method, loggers in loggers.items():\n",
    "    proc_data[method] = {\n",
    "        k: [] for k in\n",
    "        ('p', 'train/acc', 'val/acc', 'test/acc', 'rem_nodes', 'rem_edges', 'coverage')\n",
    "    }\n",
    "    m_data = proc_data[method]\n",
    "    for logger in loggers:\n",
    "        info = logger.info.copy()\n",
    "        m_data['p'].append(info['drop_p'])\n",
    "        acc = stdmean_acc(logger)\n",
    "        for k in acc:\n",
    "            m_data[k].append(acc[k])\n",
    "        train_acc = stdmean(logger, 'train/acc',\n",
    "            summarize=lambda x: {k: 100*max(v) for k, v in x.items()})\n",
    "        for k in train_acc:\n",
    "            m_data[k].append(train_acc[k])\n",
    "        train_stat = stdmean(logger, 'train/extra', summarize=extract_train_info)\n",
    "        for k in train_stat:\n",
    "            m_data[k].append(train_stat[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for _, method in enumerate(proc_data):\n",
    "    m_data = proc_data[method]\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
    "    plt.suptitle(f\"Dropping nodes by {method.upper()}\")\n",
    "    plt.ylim([55, 75])\n",
    "    for i, xlabel in enumerate(['p', 'rem_nodes', 'coverage']):\n",
    "        for k in ('train/acc', 'val/acc', 'test/acc'):\n",
    "            if isinstance(m_data[xlabel][0], list) or isinstance(m_data[xlabel][0], list):\n",
    "                xs = list(zip(*m_data[xlabel]))[0]\n",
    "            else:\n",
    "                xs = m_data[xlabel]\n",
    "            mean, std = [torch.tensor(a) for a in zip(*m_data[k])]\n",
    "            axs[i].plot(xs, mean, marker='o', label=k.split('/')[0])\n",
    "            axs[i].fill_between(xs, mean-std, mean+std, alpha=0.5, interpolate=True)\n",
    "            axs[i].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for metric, ylim in (('val/acc', None), ('test/acc', None)):\n",
    "    # data = proc_data[method]\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n",
    "    plt.suptitle(f\"arxiv-standard ({metric})\", fontsize=20)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim)\n",
    "    for i, xlabel in enumerate(['rem_nodes', 'coverage']):\n",
    "        # for k in ('train/acc', 'val/acc', 'test/acc'):\n",
    "        for k in proc_data:\n",
    "            k_data = proc_data[k]\n",
    "            if isinstance(k_data[xlabel][0], list) or isinstance(k_data[xlabel][0], list):\n",
    "                xs = list(zip(*k_data[xlabel]))[0]\n",
    "            else:\n",
    "                xs = k_data[xlabel]\n",
    "            mean, std = [torch.tensor(a) for a in zip(*k_data[metric])]\n",
    "\n",
    "            if xs[0] > xs[1]:\n",
    "                xs = list(reversed(xs))\n",
    "                mean = reversed(mean)\n",
    "                std = reversed(std)\n",
    "            xs, mean, std = xs[1:], mean[1:], std[1:]\n",
    "\n",
    "            axs[i].plot(xs, mean, marker='o', label=k.split('/')[0])\n",
    "            axs[i].fill_between(xs, mean-std, mean+std, alpha=0.1, interpolate=True)\n",
    "            axs[i].set_xlabel(xlabel, fontsize=16)\n",
    "            axs[i].autoscale(enable=True, axis='x', tight=True)\n",
    "            axs[i].tick_params(axis='y', which='major', labelsize=14)\n",
    "            axs[i].tick_params(axis='x', which='major', rotation=30, labelsize=14)\n",
    "            if i == 0:\n",
    "                axs[i].set_ylabel('accuracy', fontsize=16)\n",
    "    axs[i].legend(fontsize=16)\n",
    "    \n",
    "    if 'train' not in metric:\n",
    "        plt.savefig(f\"{name}_drop_{metric.replace('/', '_')}.pdf\", dpi=160, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(NeighborLoader(\n",
    "    data, num_neighbors=[-1]*3, shuffle=False,\n",
    "    input_nodes=train_nid, batch_size=batch_size,\n",
    "    num_workers=0\n",
    "))\n",
    "batch = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = batch.num_nodes\n",
    "e_t = torch.zeros((num_nodes,), dtype=torch.float)\n",
    "e_t[:batch.batch_size] = 1\n",
    "print(batch)\n",
    "deg = degree(batch.adj_t.coo()[0], batch.num_nodes)\n",
    "deg[deg==0] = 1\n",
    "adj = batch.adj_t.t()\n",
    "\n",
    "for num_layers in range(2, 8):\n",
    "    scores = [e_t]\n",
    "    for k in range(num_layers):\n",
    "        pi = scores[-1] / deg\n",
    "        scores.append(adj.spmm(pi.view(num_nodes, 1)).view(-1))\n",
    "\n",
    "    per_node = sum(scores[1:])\n",
    "    per_node[:batch.batch_size] = 0\n",
    "    topk = torch.topk(per_node, k=batch.batch_size*4)\n",
    "    nid = torch.sort(topk.indices).values\n",
    "    topk_sum = topk.values.sum().item()\n",
    "    all_sum = per_node.sum().item()\n",
    "\n",
    "    src, dst, _ = batch.adj_t.coo()\n",
    "    hop1 = dst[src<batch.batch_size]\n",
    "    hop1_max = dst[src==batch.batch_size-1].max().item()\n",
    "    assert hop1.max().item() == hop1_max\n",
    "    topk = nid.shape[0]\n",
    "    in_hop1 = (nid <= hop1_max).sum().item()\n",
    "    print(f\"num_layers={num_layers}\")\n",
    "    print(f\"{in_hop1}/{topk}={in_hop1/topk*100:.2f}%; {topk_sum:.0f}/{all_sum:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = iter(NeighborLoader(\n",
    "    data, num_neighbors=[-1,-1], shuffle=False,\n",
    "    input_nodes=train_nid, batch_size=batch_size,\n",
    "    num_workers=0\n",
    "))\n",
    "# next(dataloader)\n",
    "batch = next(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_random.__name__"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
